Common subdirectories: pc/pycodestyle/docs and pycodestyle/docs
diff -u -x .git pc/pycodestyle/pycodestyle.py pycodestyle/pycodestyle.py
--- pc/pycodestyle/pycodestyle.py	2018-12-03 20:41:32.000000000 -0800
+++ pycodestyle/pycodestyle.py	2018-12-03 11:39:25.000000000 -0800
@@ -1,5 +1,6 @@
 #!/usr/bin/env python
-# pycodestyle.py - Check Python source code formatting, according to PEP 8
+# pycodestyle.py - Check Python source code formatting, according to
+# PEP 8
 #
 # Copyright (C) 2006-2009 Johann C. Rocholl <johann@rocholl.net>
 # Copyright (C) 2009-2014 Florent Xicluna <florent.xicluna@gmail.com>
@@ -62,9 +63,9 @@
     from functools import lru_cache
 except ImportError:
     def lru_cache(maxsize=128):  # noqa as it's a fake implementation.
-        """Does not really need a real a lru_cache, it's just optimization, so
-        let's just do nothing here. Python 3.2+ will just get better
-        performances, time to upgrade?
+        """Does not really need a real a lru_cache, it's just
+        optimization, so let's just do nothing here. Python 3.2+ will
+        just get better performances, time to upgrade?
         """
         return lambda function: function
 
@@ -102,6 +103,7 @@
     # Methods and nested class and function.
     'method': 1,
 }
+MAX_DOC_LENGTH = 72
 REPORT_FORMAT = {
     'default': '%(path)s:%(row)d:%(col)d: %(code)s %(text)s',
     'pylint': '%(path)s:%(row)d: [%(code)s] %(text)s',
@@ -191,20 +193,21 @@
     return check
 
 
-##############################################################################
+########################################################################
 # Plugins (check functions) for physical lines
-##############################################################################
+########################################################################
 
 @register_check
 def tabs_or_spaces(physical_line, indent_char):
     r"""Never mix tabs and spaces.
 
     The most popular way of indenting Python is with spaces only.  The
-    second-most popular way is with tabs only.  Code indented with a mixture
-    of tabs and spaces should be converted to using spaces exclusively.  When
-    invoking the Python command line interpreter with the -t option, it issues
-    warnings about code that illegally mixes tabs and spaces.  When using -tt
-    these warnings become errors.  These options are highly recommended!
+    second-most popular way is with tabs only.  Code indented with a
+    mixture of tabs and spaces should be converted to using spaces
+    exclusively.  When invoking the Python command line interpreter with
+    the -t option, it issues warnings about code that illegally mixes
+    tabs and spaces.  When using -tt these warnings become errors.
+    These options are highly recommended!
 
     Okay: if a == 0:\n        a = 1\n        b = 1
     E101: if a == 0:\n        a = 1\n\tb = 1
@@ -217,7 +220,7 @@
 
 @register_check
 def tabs_obsolete(physical_line):
-    r"""For new projects, spaces-only are strongly recommended over tabs.
+    r"""On new projects, spaces-only are strongly recommended over tabs.
 
     Okay: if True:\n    return
     W191: if True:\n\treturn
@@ -231,8 +234,8 @@
 def trailing_whitespace(physical_line):
     r"""Trailing whitespace is superfluous.
 
-    The warning returned varies on whether the line itself is blank, for easier
-    filtering for those who want to indent their blank lines.
+    The warning returned varies on whether the line itself is blank,
+    for easier filtering for those who want to indent their blank lines.
 
     Okay: spam(1)\n#
     W291: spam(1) \n#
@@ -272,11 +275,11 @@
     r"""Limit all lines to a maximum of 79 characters.
 
     There are still many devices around that are limited to 80 character
-    lines; plus, limiting windows to 80 characters makes it possible to have
-    several windows side-by-side.  The default wrapping on such devices looks
-    ugly.  Therefore, please limit all lines to a maximum of 79 characters.
-    For flowing long blocks of text (docstrings or comments), limiting the
-    length to 72 characters is recommended.
+    lines; plus, limiting windows to 80 characters makes it possible to
+    have several windows side-by-side.  The default wrapping on such
+    devices looks ugly.  Therefore, please limit all lines to a maximum
+    of 79 characters. For flowing long blocks of text (docstrings or
+    comments), limiting the length to 72 characters is recommended.
 
     Reports error E501.
     """
@@ -286,8 +289,9 @@
         # Special case: ignore long shebang lines.
         if line_number == 1 and line.startswith('#!'):
             return
-        # Special case for long URLs in multi-line docstrings or comments,
-        # but still report the error when the 72 first chars are whitespaces.
+        # Special case for long URLs in multi-line docstrings or
+        # comments, but still report the error when the 72 first chars
+        # are whitespaces.
         chunks = line.split()
         if ((len(chunks) == 1 and multiline) or
             (len(chunks) == 2 and chunks[0] == '#')) and \
@@ -304,9 +308,9 @@
                     "(%d > %d characters)" % (length, max_line_length))
 
 
-##############################################################################
+########################################################################
 # Plugins (check functions) for logical lines
-##############################################################################
+########################################################################
 
 
 @register_check
@@ -314,15 +318,18 @@
                 blank_before, previous_logical,
                 previous_unindented_logical_line, previous_indent_level,
                 lines):
-    r"""Separate top-level function and class definitions with two blank lines.
+    r"""Separate top-level function and class definitions with two blank
+    lines.
 
-    Method definitions inside a class are separated by a single blank line.
+    Method definitions inside a class are separated by a single blank
+    line.
 
-    Extra blank lines may be used (sparingly) to separate groups of related
-    functions.  Blank lines may be omitted between a bunch of related
-    one-liners (e.g. a set of dummy implementations).
+    Extra blank lines may be used (sparingly) to separate groups of
+    related functions.  Blank lines may be omitted between a bunch of
+    related one-liners (e.g. a set of dummy implementations).
 
-    Use blank lines in functions, sparingly, to indicate logical sections.
+    Use blank lines in functions, sparingly, to indicate logical
+    sections.
 
     Okay: def a():\n    pass\n\n\ndef b():\n    pass
     Okay: def a():\n    pass\n\n\nasync def b():\n    pass
@@ -338,7 +345,7 @@
     E304: @decorator\n\ndef a():\n    pass
     E305: def a():\n    pass\na()
     E306: def a():\n    def b():\n        pass\n    def c():\n        pass
-    """
+    """  # noqa
     top_level_lines = BLANK_LINES_CONFIG['top_level']
     method_lines = BLANK_LINES_CONFIG['method']
 
@@ -359,7 +366,8 @@
                     ):
                 ancestor_level = indent_level
                 nested = False
-                # Search backwards for a def ancestor or tree root (top level).
+                # Search backwards for a def ancestor or tree root
+                # (top level).
                 for line in lines[line_number - top_level_lines::-1]:
                     if line.strip() and expand_indent(line) < ancestor_level:
                         ancestor_level = expand_indent(line)
@@ -444,8 +452,8 @@
 
 @register_check
 def missing_whitespace_after_import_keyword(logical_line):
-    r"""Multiple imports in form from x import (a, b, c) should have space
-    between import statement and parenthesised name list.
+    r"""Multiple imports in form from x import (a, b, c) should have
+    space between import statement and parenthesised name list.
 
     Okay: from foo import (bar, baz)
     E275: from foo import(bar, baz)
@@ -492,8 +500,8 @@
                 indent_level, previous_indent_level):
     r"""Use 4 spaces per indentation level.
 
-    For really old code that you don't want to mess up, you can continue to
-    use 8-space tabs.
+    For really old code that you don't want to mess up, you can continue
+    to use 8-space tabs.
 
     Okay: a = 1
     Okay: if a == 0:\n    a = 1
@@ -530,8 +538,8 @@
 
     When using a hanging indent these considerations should be applied:
     - there should be no arguments on the first line, and
-    - further indentation should be used to clearly distinguish itself as a
-      continuation line.
+    - further indentation should be used to clearly distinguish itself
+      as a continuation line.
 
     Okay: a = (\n)
     E123: a = (\n    )
@@ -616,7 +624,8 @@
                     yield (start, "E124 closing bracket does not match "
                            "visual indentation")
             elif close_bracket and not hang:
-                # closing bracket matches indentation of opening bracket's line
+                # closing bracket matches indentation of opening
+                # bracket's line
                 if hang_closing:
                     yield start, "E133 closing bracket is missing indentation"
             elif indent[depth] and start[1] < indent[depth]:
@@ -634,7 +643,8 @@
                 # visual indent is verified
                 indent[depth] = start[1]
             elif visual_indent in (text, str):
-                # ignore token lined up with matching one from a previous line
+                # ignore token lined up with matching one from a
+                # previous line
                 pass
             else:
                 # indent is broken
@@ -847,7 +857,7 @@
             elif text in WS_NEEDED_OPERATORS:
                 need_space = True
             elif text in UNARY_OPERATORS:
-                # Check if the operator is being used as a binary operator
+                # Check if the operator is used as a binary operator
                 # Allow unary operators: -123, -x, +1.
                 # Allow argument unpacking: foo(*args, **kwargs).
                 if (prev_text in '}])' if prev_type == tokenize.OP
@@ -893,8 +903,8 @@
     r"""Don't use spaces around the '=' sign in function arguments.
 
     Don't use spaces around the '=' sign when used to indicate a
-    keyword argument or a default parameter value, except when using a type
-    annotation.
+    keyword argument or a default parameter value, except when
+    using a type annotation.
 
     Okay: def complex(real, imag=0.0):
     Okay: return magic(r=real, i=imag)
@@ -937,17 +947,17 @@
                 parens -= 1
             elif in_def and text == ':' and parens == 1:
                 annotated_func_arg = True
-            elif parens and text == ',' and parens == 1:
+            elif parens == 1 and text == ',':
                 annotated_func_arg = False
             elif parens and text == '=':
-                if not annotated_func_arg:
-                    no_space = True
-                    if start != prev_end:
-                        yield (prev_end, message)
-                else:
+                if annotated_func_arg and parens == 1:
                     require_space = True
                     if start == prev_end:
                         yield (prev_end, missing_message)
+                else:
+                    no_space = True
+                    if start != prev_end:
+                        yield (prev_end, message)
             if not parens:
                 annotated_func_arg = False
 
@@ -958,9 +968,9 @@
 def whitespace_before_comment(logical_line, tokens):
     r"""Separate inline comments by at least two spaces.
 
-    An inline comment is a comment on the same line as a statement.  Inline
-    comments should be separated by at least two spaces from the statement.
-    They should start with a # and a single space.
+    An inline comment is a comment on the same line as a statement.
+    Inline comments should be separated by at least two spaces from the
+    statement. They should start with a # and a single space.
 
     Each line of a block comment starts with a # and a single space
     (unless it is indented text inside the comment).
@@ -1021,8 +1031,8 @@
         logical_line, indent_level, checker_state, noqa):
     r"""Place imports at the top of the file.
 
-    Always put imports at the top of the file, just after any module comments
-    and docstrings, and before module globals and constants.
+    Always put imports at the top of the file, just after any module
+    comments and docstrings, and before module globals and constants.
 
     Okay: import os
     Okay: # this is a comment\nimport os
@@ -1037,7 +1047,7 @@
     E402: a=1\nfrom sys import x
 
     Okay: if x:\n    import os
-    """
+    """  # noqa
     def is_string_literal(line):
         if line[0] in 'uUbB':
             line = line[1:]
@@ -1047,7 +1057,7 @@
 
     allowed_try_keywords = ('try', 'except', 'else', 'finally')
 
-    if indent_level:  # Allow imports in conditional statements or functions
+    if indent_level:  # Allow imports in conditional statement/function
         return
     if not logical_line:  # Allow empty lines or comments
         return
@@ -1060,11 +1070,12 @@
     elif re.match(DUNDER_REGEX, line):
         return
     elif any(line.startswith(kw) for kw in allowed_try_keywords):
-        # Allow try, except, else, finally keywords intermixed with imports in
-        # order to support conditional importing
+        # Allow try, except, else, finally keywords intermixed with
+        # imports in order to support conditional importing
         return
     elif is_string_literal(line):
-        # The first literal is a docstring, allow it. Otherwise, report error.
+        # The first literal is a docstring, allow it. Otherwise, report
+        # error.
         if checker_state.get('seen_docstring', False):
             checker_state['seen_non_imports'] = True
         else:
@@ -1075,7 +1086,8 @@
 
 @register_check
 def compound_statements(logical_line):
-    r"""Compound statements (on the same line) are generally discouraged.
+    r"""Compound statements (on the same line) are generally
+    discouraged.
 
     While sometimes it's okay to put an if/for/while with a small body
     on the same line, never do this for multi-clause statements.
@@ -1138,10 +1150,11 @@
 def explicit_line_join(logical_line, tokens):
     r"""Avoid explicit line join between brackets.
 
-    The preferred way of wrapping long lines is by using Python's implied line
-    continuation inside parentheses, brackets and braces.  Long lines can be
-    broken over multiple lines by wrapping expressions in parentheses.  These
-    should be used in preference to using a backslash for line continuation.
+    The preferred way of wrapping long lines is by using Python's
+    implied line continuation inside parentheses, brackets and braces.
+    Long lines can be broken over multiple lines by wrapping expressions
+    in parentheses.  These should be used in preference to using a
+    backslash for line continuation.
 
     E502: aaa = [123, \\n       123]
     E502: aaa = ("bbb " \\n       "ccc")
@@ -1178,8 +1191,8 @@
     is_op_token = token_type == tokenize.OP
     is_conjunction = text in ['and', 'or']
     # NOTE(sigmavirus24): Previously the not_a_symbol check was executed
-    # conditionally. Since it is now *always* executed, text may be None.
-    # In that case we get a TypeError for `text not in str`.
+    # conditionally. Since it is now *always* executed, text may be
+    # None. In that case we get a TypeError for `text not in str`.
     not_a_symbol = text and text not in "()[]{},:.;@=%~"
     # The % character is strictly speaking a binary operator, but the
     # common usage seems to be to put it next to the format parameters,
@@ -1290,10 +1303,10 @@
     E712: if arg == True:
     E712: if False == arg:
 
-    Also, beware of writing if x when you really mean if x is not None --
-    e.g. when testing whether a variable or argument that defaults to None was
-    set to some other value.  The other value might have a type (such as a
-    container) that could be false in a boolean context!
+    Also, beware of writing if x when you really mean if x is not None
+    -- e.g. when testing whether a variable or argument that defaults to
+    None was set to some other value.  The other value might have a type
+    (such as a container) that could be false in a boolean context!
     """
     match = not noqa and COMPARE_SINGLETON_REGEX.search(logical_line)
     if match:
@@ -1343,9 +1356,9 @@
     Okay: if isinstance(obj, int):
     E721: if type(obj) is type(1):
 
-    When checking if an object is a string, keep in mind that it might be a
-    unicode string too! In Python 2.3, str and unicode have a common base
-    class, basestring, so you can do:
+    When checking if an object is a string, keep in mind that it might
+    be a unicode string too! In Python 2.3, str and unicode have a
+    common base class, basestring, so you can do:
 
     Okay: if isinstance(obj, basestring):
     Okay: if type(a1) is type(b1):
@@ -1360,7 +1373,8 @@
 
 @register_check
 def bare_except(logical_line, noqa):
-    r"""When catching exceptions, mention specific exceptions when possible.
+    r"""When catching exceptions, mention specific exceptions when
+    possible.
 
     Okay: except Exception:
     Okay: except BaseException:
@@ -1379,8 +1393,8 @@
 def ambiguous_identifier(logical_line, tokens):
     r"""Never use the characters 'l', 'O', or 'I' as variable names.
 
-    In some fonts, these characters are indistinguishable from the numerals
-    one and zero. When tempted to use 'l', use 'L' instead.
+    In some fonts, these characters are indistinguishable from the
+    numerals one and zero. When tempted to use 'l', use 'L' instead.
 
     Okay: L = 0
     Okay: o = 123
@@ -1389,9 +1403,9 @@
     E741: O = 123
     E741: I = 42
 
-    Variables can be bound in several other contexts, including class and
-    function definitions, 'global' and 'nonlocal' statements, exception
-    handlers, and 'with' statements.
+    Variables can be bound in several other contexts, including class
+    and function definitions, 'global' and 'nonlocal' statements,
+    exception handlers, and 'with' statements.
 
     Okay: except AttributeError as o:
     Okay: with lock as L:
@@ -1411,7 +1425,7 @@
             if prev_text in idents_to_avoid:
                 ident = prev_text
                 pos = prev_start
-        # identifiers bound to a value with 'as', 'global', or 'nonlocal'
+        # identifiers bound to values with 'as', 'global', or 'nonlocal'
         if prev_text in ('as', 'global', 'nonlocal'):
             if text in idents_to_avoid:
                 ident = text
@@ -1430,7 +1444,8 @@
 
 @register_check
 def python_3000_has_key(logical_line, noqa):
-    r"""The {}.has_key() method is removed in Python 3: use the 'in' operator.
+    r"""The {}.has_key() method is removed in Python 3: use the 'in'
+    operator.
 
     Okay: if "alph" in d:\n    print d["alph"]
     W601: assert d.has_key('alph')
@@ -1524,7 +1539,7 @@
                     pos += 1
                     if string[pos] not in valid:
                         yield (
-                            pos,
+                            line.lstrip().find(text),
                             "W605 invalid escape sequence '\\%s'" %
                             string[pos],
                         )
@@ -1533,15 +1548,16 @@
 
 @register_check
 def python_3000_async_await_keywords(logical_line, tokens):
-    """'async' and 'await' are reserved keywords starting with Python 3.7
+    """'async' and 'await' are reserved keywords starting at Python 3.7.
 
     W606: async = 42
     W606: await = 42
-    Okay: async def read_data(db):\n    data = await db.fetch('SELECT ...')
+    Okay: async def read(db):\n    data = await db.fetch('SELECT ...')
     """
-    # The Python tokenize library before Python 3.5 recognizes async/await as a
-    # NAME token. Therefore, use a state machine to look for the possible
-    # async/await constructs as defined by the Python grammar:
+    # The Python tokenize library before Python 3.5 recognizes
+    # async/await as a NAME token. Therefore, use a state machine to
+    # look for the possible async/await constructs as defined by the
+    # Python grammar:
     # https://docs.python.org/3/reference/grammar.html
 
     state = None
@@ -1556,14 +1572,15 @@
                     state = ('await', start)
         elif state[0] == 'async_stmt':
             if token_type == tokenize.NAME and text in ('def', 'with', 'for'):
-                # One of funcdef, with_stmt, or for_stmt. Return to looking
-                # for async/await names.
+                # One of funcdef, with_stmt, or for_stmt. Return to
+                # looking for async/await names.
                 state = None
             else:
                 error = True
         elif state[0] == 'await':
             if token_type in (tokenize.NAME, tokenize.NUMBER, tokenize.STRING):
-                # An await expression. Return to looking for async/await names.
+                # An await expression. Return to looking for async/await
+                # names.
                 state = None
             else:
                 error = True
@@ -1585,9 +1602,64 @@
         )
 
 
-##############################################################################
+########################################################################
+@register_check
+def maximum_doc_length(logical_line, max_doc_length, noqa, tokens):
+    r"""Limit all doc lines to a maximum of 72 characters.
+
+    For flowing long blocks of text (docstrings or comments), limiting
+    the length to 72 characters is recommended.
+
+    Reports warning W505
+    """
+    if max_doc_length is None or noqa:
+        return
+
+    prev_token = None
+    skip_lines = set()
+    # Skip lines that
+    for token_type, text, start, end, line in tokens:
+        if token_type not in SKIP_COMMENTS.union([tokenize.STRING]):
+            skip_lines.add(line)
+
+    for token_type, text, start, end, line in tokens:
+        # Skip lines that aren't pure strings
+        if token_type == tokenize.STRING and skip_lines:
+            continue
+        if token_type in (tokenize.STRING, tokenize.COMMENT):
+            # Only check comment-only lines
+            if prev_token is None or prev_token in SKIP_TOKENS:
+                lines = line.splitlines()
+                for line_num, physical_line in enumerate(lines):
+                    if hasattr(physical_line, 'decode'):  # Python 2
+                        # The line could contain multi-byte characters
+                        try:
+                            physical_line = physical_line.decode('utf-8')
+                        except UnicodeError:
+                            pass
+                    if start[0] + line_num == 1 and line.startswith('#!'):
+                        return
+                    length = len(physical_line)
+                    chunks = physical_line.split()
+                    if token_type == tokenize.COMMENT:
+                        if (len(chunks) == 2 and
+                                length - len(chunks[-1]) < MAX_DOC_LENGTH):
+                            continue
+                    if len(chunks) == 1 and line_num + 1 < len(lines):
+                        if (len(chunks) == 1 and
+                                length - len(chunks[-1]) < MAX_DOC_LENGTH):
+                            continue
+                    if length > max_doc_length:
+                        doc_error = (start[0] + line_num, max_doc_length)
+                        yield (doc_error, "W505 doc line too long "
+                                          "(%d > %d characters)"
+                               % (length, max_doc_length))
+        prev_token = token_type
+
+
+########################################################################
 # Helper functions
-##############################################################################
+########################################################################
 
 
 if sys.version_info < (3,):
@@ -1684,14 +1756,14 @@
             rv[path].update(range(row, row + nrows))
         elif line[:3] == '+++':
             path = line[4:].split('\t', 1)[0]
-            # Git diff will use (i)ndex, (w)ork tree, (c)ommit and (o)bject
-            # instead of a/b/c/d as prefixes for patches
+            # Git diff will use (i)ndex, (w)ork tree, (c)ommit and
+            # (o)bject instead of a/b/c/d as prefixes for patches
             if path[:2] in ('b/', 'w/', 'i/'):
                 path = path[2:]
             rv[path] = set()
-    return dict([(os.path.join(parent, path), rows)
-                 for (path, rows) in rv.items()
-                 if rows and filename_match(path, patterns)])
+    return dict([(os.path.join(parent, filepath), rows)
+                 for (filepath, rows) in rv.items()
+                 if rows and filename_match(filepath, patterns)])
 
 
 def normalize_paths(value, parent=os.curdir):
@@ -1739,9 +1811,9 @@
         return _eol_token(token) or (token[0] == tokenize.COMMENT and
                                      token[1] == token[4])
 
-##############################################################################
+########################################################################
 # Framework to run all checks
-##############################################################################
+########################################################################
 
 
 class Checker(object):
@@ -1758,6 +1830,7 @@
         self._logical_checks = options.logical_checks
         self._ast_checks = options.ast_checks
         self.max_line_length = options.max_line_length
+        self.max_doc_length = options.max_doc_length
         self.multiline = False  # in a multiline string?
         self.hang_closing = options.hang_closing
         self.verbose = options.verbose
@@ -1918,7 +1991,7 @@
                     self.report_error(lineno, offset, text, check)
 
     def generate_tokens(self):
-        """Tokenize the file, run physical line checks and yield tokens."""
+        """Tokenize file, run physical line checks and yield tokens."""
         if self._io_error:
             self.report_error(1, 0, 'E902 %s' % self._io_error, readlines)
         tokengen = tokenize.generate_tokens(self.readline)
@@ -1933,7 +2006,7 @@
             self.report_invalid_syntax()
 
     def maybe_check_physical(self, token):
-        """If appropriate (based on token), check current physical line(s)."""
+        """If appropriate for token, check current physical line(s)."""
         # Called after every token, but act only on end of line.
         if _is_eol_token(token):
             # Obviously, a newline token ends a single physical line.
@@ -1941,15 +2014,16 @@
         elif token[0] == tokenize.STRING and '\n' in token[1]:
             # Less obviously, a string that contains newlines is a
             # multiline string, either triple-quoted or with internal
-            # newlines backslash-escaped. Check every physical line in the
-            # string *except* for the last one: its newline is outside of
-            # the multiline string, so we consider it a regular physical
-            # line, and will check it like any other physical line.
+            # newlines backslash-escaped. Check every physical line in
+            # the string *except* for the last one: its newline is
+            # outside of the multiline string, so we consider it a
+            # regular physical line, and will check it like any other
+            # physical line.
             #
             # Subtleties:
-            # - we don't *completely* ignore the last line; if it contains
-            #   the magical "# noqa" comment, we disable all physical
-            #   checks for the entire multiline string
+            # - we don't *completely* ignore the last line; if it
+            #   contains the magical "# noqa" comment, we disable all
+            #   physical checks for the entire multiline string
             # - have to wind self.line_number back because initially it
             #   points to the last line of the string, and we want
             #   check_physical() to give accurate feedback
@@ -2109,7 +2183,7 @@
 
 
 class FileReport(BaseReport):
-    """Collect the results of the checks and print only the filenames."""
+    """Collect the results of the checks and print the filenames."""
 
     print_filename = True
 
@@ -2141,7 +2215,7 @@
         return code
 
     def get_file_results(self):
-        """Print the result and return the overall count for this file."""
+        """Print results and return the overall count for this file."""
         self._deferred_print.sort()
         for line_number, offset, code, text, doc in self._deferred_print:
             print(self._fmt % {
@@ -2160,8 +2234,8 @@
                 print('    ' + doc.strip())
 
             # stdout is block buffered when not stdout.isatty().
-            # line can be broken where buffer boundary since other processes
-            # write to same file.
+            # line can be broken where buffer boundary since other
+            # processes write to same file.
             # flush() after print() to avoid buffer boundary.
             # Typical buffer size is 8192. line written safely when
             # len(line) < 8192.
@@ -2279,7 +2353,7 @@
     def excluded(self, filename, parent=None):
         """Check if the file should be excluded.
 
-        Check if 'options.exclude' contains a pattern that matches filename.
+        Check if 'options.exclude' contains a pattern matching filename.
         """
         if not self.options.exclude:
             return False
@@ -2307,8 +2381,8 @@
     def get_checks(self, argument_name):
         """Get all the checks for this category.
 
-        Find all globally visible functions where the first argument name
-        starts with argument_name and which contain selected tests.
+        Find all globally visible functions where the first argument
+        name starts with argument_name and which contain selected tests.
         """
         checks = []
         for check, attrs in _checks[argument_name].items():
@@ -2324,8 +2398,8 @@
                           usage="%prog [options] input ...")
     parser.config_options = [
         'exclude', 'filename', 'select', 'ignore', 'max-line-length',
-        'hang-closing', 'count', 'format', 'quiet', 'show-pep8',
-        'show-source', 'statistics', 'verbose']
+        'max-doc-length', 'hang-closing', 'count', 'format', 'quiet',
+        'show-pep8', 'show-source', 'statistics', 'verbose']
     parser.add_option('-v', '--verbose', default=0, action='count',
                       help="print status messages, or debug with -vv")
     parser.add_option('-q', '--quiet', default=0, action='count',
@@ -2361,6 +2435,10 @@
                       default=MAX_LINE_LENGTH,
                       help="set maximum allowed line length "
                            "(default: %default)")
+    parser.add_option('--max-doc-length', type='int', metavar='n',
+                      default=None,
+                      help="set maximum allowed doc line length and perform "
+                           "these checks (unchecked if not set)")
     parser.add_option('--hang-closing', action='store_true',
                       help="hang closing bracket instead of matching "
                            "indentation of opening bracket's line")
@@ -2383,12 +2461,13 @@
 def read_config(options, args, arglist, parser):
     """Read and parse configurations.
 
-    If a config file is specified on the command line with the "--config"
-    option, then only it is used for configuration.
+    If a config file is specified on the command line with the
+    "--config" option, then only it is used for configuration.
 
-    Otherwise, the user configuration (~/.config/pycodestyle) and any local
-    configurations in the current directory or above will be merged together
-    (in that order) using the read method of ConfigParser.
+    Otherwise, the user configuration (~/.config/pycodestyle) and any
+    local configurations in the current directory or above will be
+    merged together (in that order) using the read method of
+    ConfigParser.
     """
     config = RawConfigParser()
 
@@ -2457,10 +2536,10 @@
 
 def process_options(arglist=None, parse_argv=False, config_file=None,
                     parser=None, verbose=None):
-    """Process options passed either via arglist or via command line args.
+    """Process options passed either via arglist or command line args.
 
-    Passing in the ``config_file`` parameter allows other tools, such as flake8
-    to specify their own options to be processed in pycodestyle.
+    Passing in the ``config_file`` parameter allows other tools, such as
+    flake8 to specify their own options to be processed in pycodestyle.
     """
     if not parser:
         parser = get_parser()
Common subdirectories: pc/pycodestyle/testsuite and pycodestyle/testsuite
